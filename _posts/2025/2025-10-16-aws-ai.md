---
layout: post
title:  "AWS AI Pracioner"
date:   2025-10-16
categories: beyond
permalink: /:categories/aws-ai
---


<p>Index:<em> 
	<a href="#subsets">Ai Subsets</a> > 
	<a href="#ml">Machine Learning</a> > 
	<a href="#fm">Foundation Models</a> > 
</em></p>


This post focuse in AWS AI. If you need more detail about cloud infra you can see the [AWS Conteps](https://fabiana2611.github.io/infra/aws-concepts) post.

<br />
<hr>
<br />
<h2 id="subsets">AI Subsets</h2>

<p><b><center><em>AI > Machine Learning > Deep Learning > Generative AI</em></center></b></p>


<p><b>Artificial Intelligence (AI)</b></p>

<ul>
	<li><em>Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.</em> <a href="https://www.ibm.com/think/topics/artificial-intelligence">[1]</a></li>
	<li>Techniques:
		<ul>
			<li><a href="https://aws.amazon.com/what-is/computer-vision/">Computer Vision:</a> based on the computer video analysis of images in real time. Whereas computer vision involves <u>interpreting and understanding</u> the content of images to make decisions, image processing focuses on enhancing and manipulating images for visual quality. CNNs are used for single image analysis and RNNs are used for video analysis. ResNet is a deep neural network architecture used mainly in computer vision tasks, such as image classification and object detection</li>
			<li><a href="https://www.ibm.com/think/topics/deep-learning">Deep Learning:</a> uses multilayered neural networks, called deep neural networks, to simulate the complex decision-making power of the human brain. CNNs are a type of deep learning model</li>
			<li><a href="https://www.ibm.com/think/topics/natural-language-processing">Natural Language Processing (NLP):</a> uses machine learning to enable computers to understand and communicate with human language</li>
		</ul>
	</li>
</ul>



<p><b>Machine Learning (ML)</b></p>

<ul>
	<li><a href="https://aws.amazon.com/what-is/machine-learning/">Machine Learning</a> creates models from training an algorithm to make predictions or decisions based on data.</li>
	<li>The performance is improved when they are exposed to more data</li>
	<li>Machine Learning models can be deterministic (e.g Decision Trees) or probabilistic (e.g Bayesian Networks) or a mix of both (e.g neural networks and random forests) </li>
	<li>Use cases: spam detection, recommendation systems, predictive analytics</li>
</ul>


<p><b>Deep Learning (DL)</b></p>

<ul>
	<li>Subset of ML</li>
	<li>It utilizes artificial <a href="https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">neural networks</a> with multiple layers to model complex patterns in data. Deep neural networks can automatically discover representations needed for future detection</li>
	<li>Use cases: image, speech recognition, NLP, autonomous vehicles</li>
	<li>Involves using large datasets to adjust the weights and biases of a neural network through multiple iterations</li>
</ul>


<p><b>Generative AI (GenAI)</b></p>

<ul>
	<li><a href="https://research.ibm.com/blog/what-is-generative-AI">GenAI</a>: generating new content similar to the data they were trained on. They rely on the Transformer Architecture</li>
	<li>Unlabeled Data > Foundation Model > used for general tasks (chatbot, text generation, etc)</li>
	<li>Large Language Models (LLM): Type of AI designed to generate coherent human-like text (GPT-4)</li>
	<li>Foundation Models: trained on a wide variety of input data (GPT-4o)</li>
	<li>Generative Language Models: interact with the LLM by a prompt. The model generate new content. Non-deterministic.</li>
	<li>Example of Models: GPT for text generation and DALL-E for image creation</li>
</ul>


<!-- ####################################### -->

<br />
<hr>
<br />
<h2 id="ml">Machine Learning</h2>

<b>Types:</b>
<ul>
	<li>Supervised Learning (labeled) <a href="https://www.ibm.com/think/topics/supervised-learning">[1]</a><a href=" https://aws.amazon.com/compare/the-difference-between-machine-learning-supervised-and-unsupervised/">[2]</a>: involves training models on labeled data to make predictions. It can be Classification, Regression (e.g: Linear regression - predicting a price; spam detection), Neural Network</li>
	<li><a href="https://www.ibm.com/think/topics/unsupervised-learning">Unsupervised Learning</a> (groups without label): clustering, Association rule learning, Probability density, Anomaly detection, dymnesionality regression, dymnesionality reduction</li>
	<li><a href="https://www.ibm.com/think/topics/semi-supervised-learning">Semi-supervised</a> (mix) (e.g speech recognition, Document classification, Fraud Detection, Sentiment analysis)</li>
	<li><a href="https://www.ibm.com/think/topics/self-supervised-learning">Self-supervised</a> (try  by itself): create its own label - Predict and infer (e.g Gmail smart compose)</li>
	<li><a href="https://aws.amazon.com/what-is/reinforcement-learning/">Reinforcement Learning</a> (try fit - learn by success and failure): focuses on an agent learning optimal actions through interactions with the environment and feedback (robotics, game playing, and industrial automation)</li>
</ul>

<a href="https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.html">Algorithms:</a>
<ul>
	<li>Decision Trees are highly interpretable models that provide a clear and straightforward visualization of the decision-making process (deterministic). </li>
	<li>Logistic Regression is primarily designed for binary classification problems. It can be adapted for multiclass classification but it may not perform effectively with a large number of categories or a complex dataset.</li>
	<li>Neural Networks involves multiple layers of neurons and nonlinear transformations.</li>
	<li>Support Vector Machines (SVMs) are effective for classification tasks, especially in high-dimensional spaces. SVMs create a hyperplane to separate classes.</li>
	<li><a href="https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/">K-Means</a> is an unsupervised learning algorithm used for clustering data points into groups</li>
	<li>KNN is a supervised learning algorithm used for classifying data points based on their proximity to labeled examples</li>
</ul>


<h3>Process</h3>

<p><em><b>Pipeline:</b> Fetch -> Clean -> Prepare -> Train and tune model -> Evaluate model -> Deploy to prod </em></p>

<a href="https://aws.amazon.com/blogs/machine-learning/create-train-test-and-validation-splits-on-your-data-for-machine-learning-with-amazon-sagemaker-data-wrangler/">Data:</a>
<ul>
	<li>The training set is used to train the model</li>
	<li>The validation set (optional) is used for periodically measure model performance as training is happening and also tune any hyperparameters of the model, selecting the best model during the training process</li>
	<li>The test set is used for evaluating the final performance of the model on unseen data (how well the model generalizes)</li>
</ul>

<p><em><a href="https://aws.amazon.com/what-is/machine-learning/">Process: </a> Collect data > [Pre-process data + Data Preparation] (repeat ETL operation until data is prepared) -> [Apply ML Algorithm to ETL Data + Potential Models] (repeat to find the best model) > Deploy selected model </em></p>

<p><b>Data Collection:</b> </p>
<ul>
	<li>Gathering the necessary data from various sources (Fetch)</li>
</ul>

<b>Data Preprocessing:</b> 
<ul>
	<li>Cleaning and preparing the data for training</li>
	<li>Handle missing values(filling or removing), Inconsistent data (standardize data types, units of measurement), Duplicate (removing or merging) </li>
	<li><a href="https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/feature-engineering.html">Feature Enginnering</a> can help to transform insufficient raw data into a format that is easier for a ML model to learn from
		<ul>
			<li>selecting, modifying, or creating features from raw data to improve the performance of machine learning models</li>
			<li>for structured data often involves tasks such as normalization and handling missing values, while for unstructured data, it involves tasks such as tokenization and vectorization</li>
		</ul>
	</li>
	<li>Techniques: 
		<ul>
			<li>Feature selection: selecting a subset of the most relevant features from the original dataset </li>
			<li>Feature Extraction: transforming the data into a new feature space </li>
			<li>Dimensionality Reduction;</li>
			<li>Category Enconding;</li>
			<li>Data augmentation: artificially increase the size and variability of the training dataset by creating modified versions of the existing data</li>
		</ul>
	</li>	
	<li><b>Generating Data</b>:
		<ul>
			<li><a href="https://aws.amazon.com/blogs/machine-learning/exploratory-data-analysis-feature-engineering-and-operationalizing-your-data-flow-into-your-ml-pipeline-with-amazon-sagemaker-data-wrangler/">Exploratory Data Analysis (EDA)</a>:
				<ul>
					<li>Purpose: Identify patterns, correlations, and anomalies in data before any model training or analysis; formulate potential hypothesis</li>
					<li>Techniques: creating visual charts; summarizing the main features</li>
					<li>This phase is crucial for understanding the datasetâ€™s structure and characteristics.</li>
				</ul>
			</li>
			<li>Correlation Matrix: quantify relationships between variables</li>
		</ul>
	</li>
</ul>

<b>Model Training:</b> 
<ul>
	<li>Using the preprocessed data to train a machine learning algorithm, resulting in a trained model.</li>
	<li>Parameters: used to represent relationship between the data</li>
	<li>Hyperparameter<a href="https://www.ibm.com/think/topics/hyperparameter-tuning">[1]</a><a href="https://aws.amazon.com/what-is/overfitting/">[2]</a> 
		<ul>
			<li>Allows adjust the settings that control the learning process of the model.</li>
			<li>Configured before training and they remain fixed during training; they can impact the speed and quality of the learning process;</li>
			<li>Common hyperparameters among algorithms: Learning Rate; Batch Size; <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-fine-tune.html">Number of Epochs</a></li>
			<li>Tuning a Model: adjusting a machine learning model's configurations to improve its performance on a specific task</li>
			<li>Poor ML models may be caused by hyperparameters: the optimal values can be find by Grid Search (test all possible combination) or Random Search (random combination)</li>
		</ul>
	</li>
</ul>

<b>Model Evaluation:</b> 
<ul>
	<li>Assessing the performance of the trained model using a separate test set to ensure it generalizes well to new, unseen data.</li>
	<li>Metrics used to evaluate the effectiveness of a classification system: accuracy, precision, recall, or F1 score. </li>
</ul>


<h3>Metrics</h3>

Metrics for classification Models: <a href="https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall">[1]</a><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-metrics-validation.html">[2]</a>
<ul>
	<li>Accuracy; Precision; Recall; F1 score -> measure using Confusion Matrix </li>
	<li>Confusion matrix: designed to evaluate the performance of classification models by displaying the number of true positives, true negatives, false positives, and false negatives (correctly or incorrectly classification).</li>
	<li>Precision: Measures the accuracy of the positive predictions, calculated as the ratio of true positives to the sum of true positives and false positives.</li>
	<li>Recall (Sensitivity): Measures the ability of the classifier to identify all positive instances, calculated as the ratio of true positives to the sum of true positives and false negatives.</li>
	<li>F1-Score: The harmonic mean of Precision and Recall, providing a single metric that balances both concerns.</li>
</ul>

<a href="https://developer.nvidia.com/blog/a-comprehensive-overview-of-regression-evaluation-metrics/">Metrics of Regression Models:</a>
<ul>
	<li>Mean Absolute Error (MAE): measures the average magnitude of errors in a set of predictions (accuracy of a continuous variable's predictions)</li>
	<li>Mean Square Error (MSE)</li>
	<li>Root Mean Square Error (RMSE): calculating the square root of the average squared differences between predicted and actual values.</li>
	<li>RË†2 (R Squared)</li>
</ul>

<b>For both:</b>
<ul>
	<li>Average Response Time: measures how long it takes for the model to process input data and generate a prediction</li>
	<li>Number of Training Sessions</li>
	<li>Customer Feedbacks</li>
	<li>Return on Investment (ROI)</li>
</ul>



<h3>AWS Managed AI/ML Services and Applications</h3>

<p><a href="https://aws.amazon.com/ai/services/">AWS AI Services:</a> Support real-time and batch. Pay by use</p>

<b>Vision:</b>
<ul>
	<li><u>Rekognition:</u> images and videos using ML 
		<ul>
			<li>Use cases: Labeling, Content Moderation, Text Detection, Face Detection</li>
			<li>Rekognition Analysis: tracking people, analyzing Faces, Facial Emotions</li>
			<li>Rekognition Detection: objects, scenes, text, brands, activities, inappropriate content</li>
			<li>Rekognition Custom Moderation Adaptor to tailor the moderation process to your needs -> Providers training dataset with labelled images</li>
			<li>Custom Labels: Label your training images and upload them to Amazon Rekognition</li>			
		</ul>
	</li>
	<li><u>Textract</u><a href="https://docs.aws.amazon.com/textract/latest/dg/what-is.html">[1]</a>:   
		<ul>
			<li>designed for extracting text, handwriting, and structured data from scanned documents (scanned forms, images, tables and grids).</li>
			<li>Data Process: Real-time Analysis (single doc in a synchronous fashion); Async Analysis (multiple docs in batch process)</li>
			<li>Form extraction: extract data from forms and documents with structured layouts</li>
			<li>Document analysis: extract text, tables, and other elements from documents. This feature provides a comprehensive analysis of the document, including identifying the layout and structure</li>
			<li>Key-value pairs: extract structured data such as key-value pairs from documents like invoices and receipts</li>
			<li>Table detection: identify and extract tables from documents</li>
		</ul>
	</li>
</ul>

<b>Language:</b>
<ul>
	<li>Comprehend <a href="https://docs.aws.amazon.com/comprehend/latest/dg/what-is.html">[1]</a><a href="https://aws.amazon.com/comprehend/features/">[2]</a> : Analyze Text Data
		<ul>
			<li>Use Natural Language processing (NPL)</li>
			<li>It is designed to analyze unstructured text and identify entities (name, date, etc)</li>
			<li>Amazon Comprehend can classify documents based on the content</li>
			<li>Get insights by classifying data</li>
			<li>Break down text via: tokenization; Parts of Speech (PoS)</li>
			<li>Custom Classification providing a training dataset with labelled categories</li>
			<li>Custom Entity Recognition</li>
			<li>Data Process: Real-time analysis</li>
			<li>Use cases: unstructured clinical data</li>
			<li>uses machine learning to find insights and relationships in the text</li>
			<li>Amazon Comprehend Medical detects and returns useful information in unstructured clinical text. Comprehend Medical is HIPAA-eligible and can quickly identify protected health information (PHI)</li>
			<li>The real-time API provided by Amazon Comprehend is specifically designed for applications that require on-the-fly analysis (e.g live feedback monitoring)
		</ul>
	</li>
	<li><u>Translate:</u> Natural and accurate language translation</li>
</ul>

<b>Speech:</b>
<ul>
	<li><u>Polly</u> <a href="https://docs.aws.amazon.com/polly/">[1]</a><a href="https://docs.aws.amazon.com/polly/latest/dg/supportedtags.html">[2]</a>: text-to-speech
		<ul>
			<li>use cases: Audiobook</li>
			<li>Data Process: Real-time, bach </li>
			<li>Use deep learning</li>
			<li>used to deploy high-quality, natural-sounding human voices in dozens of languages</li>
			<li>Interactive voice response (IVR) system that dynamically adjusts speech output based on user inputs</li>
			<li>Speech Synthesis Markup Language (SSML) allows the developer to control various aspects of speech</li>
		</ul>
	</li>
	<li><u>Transcribe:</u> Speech-to-text
		<ul>
			<li>Data Process: real-time; batch</li>
			<li>Automized by Automatic Speech Recognition (ASR) Service</li>
			<li>Improving Accuracy: custom vocabulary</li>
			<li>Custom Language Models (for context)</li>
			<li>use cases: closed caption and subtitles; transcribe customer service calls</li>
			<li><a href="https://aws.amazon.com/transcribe/medical/">Amazon Transcribe Medical</a> is an automatic speech recognition (ASR) service that makes it easy for you to add medical speech-to-text capabilities to your voice-enabled applications</li>
		</ul>
	</li>
</ul>

<b>Chatbots</b>
<ul>
	<li><u>Lex:</u> converts speech to text to build chat bots
		<ul>
			<li>The essence of a Bot Conversation: Intents (e.g order a coffe); Slots (variables for detail; e.g. size)</li>
			<li>Key integration: Lambda, Connect, Comprehend</li>
		</ul>
	</li>	
</ul>


<a href="https://aws.amazon.com/forecast/">Forecasting:</a> 
<ul>
	<li>use historical data to predict future trends</li>
	<li>Labelled training dataset</li>
	<li>Uses statistical and machine learning algorithms to deliver highly accurate time-series forecasts. </li>
	<li>Use case: Retail demand planning; Supply chain planning; Resource planning; Operational planning</li>
	<li><a href="https://aws.amazon.com/kendra/faqs/">Kendra</a>: powerful search service
		<ul>
			<li>NLP; Contextual relevance</li>
			<li>Data sources: MS SharePoint, Google Drive, S3, RDS</li>
			<li>Semantic search: It provides accurate and relevant search results from a variety of document types.</li>
		</ul>			
	</li>
</ul>

<b>Recommendation</b> <a href="https://aws.amazon.com/personalize/faqs/">[1]</a><a href="https://docs.aws.amazon.com/personalize/latest/dg/recommendations.html">[2]</a>
<ul>
	<li>Personalize: uses your data to generate product and content recommendations for your users</li>
	<li>Recipes (algorithms of Personalize): USER_PERSONALIZATION (based on activities); PERSONALIZED_RANKING; PERSONALIZED_ACTIONS; POPULAR_ITEMS; USER_SEGMENTATION</li>
	<li>Use cases: retail stores, media and entertainment</li>
</ul>

<b>Others ML application</b>
<ul>
	<li>SageMaker</li>
	<li>Bedrock</li>
</ul>

<b>AWS chip:</b>
<ul>
	<li><a href="https://aws.amazon.com/machine-learning/trainium/">AWS Trainium:</a> AWS purpose-built for deep learning (DL) training of 100B+ parameter models.</li>
	<li><a href="https://aws.amazon.com/machine-learning/inferentia/">AWS Inferentia</a>: deliver high-performance inference at a low cost. </li>
	<li>Accelerated Computing P type instances - powered by high-end GPUs like NVIDIA Tesla, are optimized for maximum computational throughput, particularly for machine learning and HPC tasks. However, they consume significant amounts of power and are not specifically designed with energy efficiency in mind</li>
	<li>Accelerated Computing G type instances - designed for graphics-heavy applications like gaming, rendering, or video processing. While they offer high computational power for specific tasks, they are not specifically optimized for energy efficiency or low environmental impact</li>
	<li>Compute Optimized C type instances - designed to maximize compute performance for applications such as web servers, gaming, and scientific modeling. While they provide excellent compute power, they are not optimized for energy efficiency</li>
</ul>


<!-- ####################################### -->

<br />
<hr>
<br />
<h2 id="fm">Foundation Models</h2>

<a href="https://www.ibm.com/think/topics/foundation-models">Foundation Models</a>:
<ul>
	<li>Large, general-purpose pre-trained models</li>
	<li>They can be adapted for various tasks</li>
	<li>ChatGPT: trained model</li>
	<li>A multimodal model can accept a mix of input types such as audio/text and create a mix of output types such as video/image</li>
</ul>

Large language models (LLM)<a href="https://www.ibm.com/think/topics/large-language-models?">[1]</a><a href="https://aws.amazon.com/what-is/large-language-model/">[2]</a> 
<ul>
	<li>It is a subset of foundation models that can understand and generate human language</li>
	<li>Focused on language-based tasks (summarization, text generation, classification, open-ended conversation, and information extraction)</li>
	<li>They are very large deep learning models that are pre-trained on vast amounts of data</li>
	<li>It uses DL to analyze and predict word sequences</li>
	<li>Examples: OpenAI's generative pre-trained transformer (GPT) models</li>
	<li>Services for LLM: AWS Bedrock and <a href="https://aws.amazon.com/sagemaker/jumpstart/">Amazon SageMaker JumpStart</a></li>
</ul>

Data: 
<ul>
 	<li>Training Data: Inputs variables (e.g image) and Target Variables (e.g label that identify the image)</li>
 	<li>Type of data: Structured data (Tabular) and Unstructured data (text, images, audio)</li>
</ul>

Goals of training:
<ul>
	<li>Training data --> Model --> Trained Model</li>
	<li>New Data --> Trained model --> Correct label (prediction/inference)</li>
	<li>Goals of training for GenAI: input --> Trained Model --> Content Generation</li>
</ul>

Model Fit: How accurate do predictions (Probability) <a href="https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html">[1]</a><a href="https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html">[2]</a><a href="https://aws.amazon.com/what-is/overfitting/">[3]</a>
<ul>
	<li><b>Underfitting</b> occurs when a model cannot capture the underlying patterns in the data, resulting in poor performance on both the training data and new data. When underfit models experience high bias they give inaccurate results.</li>
	<li><b>Overfitting</b> happens when a model learns the training data too well, including noise and outliers, leading to excellent performance on the training data but poor generalization to new, unseen data. When overfit models experience high variance they give accurate results. Prevention: cross-validation (dividing the data into multiple training and validation sets), regularization (L1 and L2 - penalization), and pruning to simplify the model and improve its generalization</li>
	<li>It's necessary a balance</li>
</ul>



<h3>Design Considerations for Foundation Model Applications</h3>

Criteria used to select Foundation Model:
<ul>
  <li>Modality: type of data a model is trained to handle (text, images, audios)</li>
  <li>Latency: real-time, batch</li>
  <li>Multilingual support</li>
  <li>Complexity</li>
  <li>Customization</li>
  <li>Input, output length</li>
</ul>

<a href="https://docs.aws.amazon.com/bedrock/latest/userguide/inference-parameters.html">Inference Parameter:</a>
<ul>
	<li>Temperature: regulates the <u>creativity</u> of the model's responses (0 - more deterministic | 1 - creative)</li>
	<li>Top-P: represents the <u>percentage</u> of most likely candidates that the model considers for the next token.</li>
	<li>Top-K: represents the <u>number</u> of most likely candidates that the model considers for the next token. helps introduce controlled diversity in the generated text while avoiding low-probability and nonsensical outputs</li>
	<li>Stop sequences specify the <u>sequences of characters that stop the model from generating further tokens</u>.</li>
	<li>Input/output length: how much information the model can process and generate</li>
	<li><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/inference-parameters.html">Length</a>: limit the length of the response (Response length, Penalties, Stop sequences)</li>
</ul>


Retrieval-augmented Generation (RAG)<a href="https://research.ibm.com/blog/retrieval-augmented-generation-RAG">[1]</a><a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/">[2]</a>
<ul>
	<li>It is the process of optimizing the output of a large language model (LLM)</li>
	<li>External knowledge source (e.g database, documents)</li>
	<li>RAG extends the capabilities of LLMs to specific domains without retrain the model</li>
	<li>Combines retrieval generation</li>
</ul>

<a href="https://www.ibm.com/think/topics/vector-database">Vector Storage Solution</a>
<ul>
	<li>Foundation models process inputs and convert them into vectors embeddings, or mathematical representations of data</li>
	<li>The embeddings capture the semantic meaning of inputs</li>
	<li>Embeddings are how AI models represent data in a way that machines can understand</li>
	<li>Vectors are the numerical array of embeddings</li>
	<li>Vector databases store and manage embeddings</li>
	<li>Vector databases uses vector seach algorithms to index and query vector embeddings based on their similarity</li>
</ul>

AWS Services:
<ul>
	<li>Amazon OpenSearch: Combines vector and text search. Use case: search engines, recommendation systems</li>
	<li>Amazon Aurora: Scalable, relational database capabilities. Use case: E-commerce, real-time recommendations</li>
	<li>Amazon Neptune: Graph-based queries for embedding data. Use case: Knowledge graphs, social networks</li>
	<li>Amazon Document DB: Schema-less storage for varied embeddings. Use case: Chatbots, personalization</li>
	<li>Amazon RDS for PostgreSQL: PGVector extension for similarity searches. Use case: Multimedia search, AI applications.</li>
</ul>

Cost trad-offs for customization:
<ul>
	<li>Pre-training: high costs, full controll over model behavior</li>
	<li>Fine-tuning: moderate costs, balances control and efficiency</li>
	<li>in-context learning: low costs, great for flexibility</li>
	<li>RAG: cost-effective, uses external data for specialized tasks</li>
</ul>

Agents:
<ul>
	<li>A way to extend the functionality of foundation models by enabling them to automate multi-step workflow</li>
	<li>They follow predefined instructions, interact with data sources and generate outputs based on goals.</li>
	<li>Ideal for tasks with multi-step automation</li>
	<li>Integrate with RAG</li>
	<li>Dynamically generate code</li>
	<li>Orchestrate tasks via API calls</li>
</ul>



<h3>Training and Fine-tuning Foundation Models</h3>

Pre-training:
<ul>
	<li>initial stage where the model learns from unstructured data</li>
	<li>goal: understand patterns or generating coherent responses</li>
	<li>usually done by large company like AWS</li>
	<li>Continuous pre-trained is a process that allows LLM to learn new information while retaining what they've already learned</li>
</ul>

<a href="https://www.ibm.com/think/topics/fine-tuning">Fine-tuning</a>:
<ul>
	<li>Customizing pre-trained model with specific data (particular use cases)</li>
	<li>Methods: Instruction Tuning, <a href="https://aws.amazon.com/what-is/transfer-learning/">Transfer learning</a> (allows a model to utilize the knowledge learned from one task or dataset to improve its performance on a new, but related task)</li>
	<li>Preparing Data: Data curation; Data Governance; Data size and Representativeness; Data Labeling; Reinforcement Learning From Human Feedback (RLHF)</li>
</ul>



<h3>Evaluating Foundation Model Performance</h3>

<p>Desired performance metrics: accuracy, fairness, usability</p>

Methods:
<ul>
	<li>Human Evaluation:
		<ul> 
			<li>access outputs based on specific criteria</li>
			<li>time-consuming and subjective</li>
		</ul>
	</li>
	<li>Banchmark Datasets
		<ul>
			<li>prebuilt collections of labeled data used to test model performance against industry standards</li>
			<li>objective and require less administrator effort</li>
		</ul>
	</li>
</ul>

Metrics: <a href="https://tutorialsdojo.com/methods-in-evaluating-foundation-model-performance/">[1]</a><a href="https://aws.amazon.com/blogs/machine-learning/build-a-multilingual-automatic-translation-pipeline-with-amazon-translate-active-custom-translation/">[2]</a>
<ul>
	<li>Accuracy is a broad metric typically used to evaluate classification tasks where the model's <u>output is compared against the correct label</u>. </li>
	<li>ROUGE (Recall-oriented Understudy for Gisting Evaluation): measures the <u>overlap between generated and reference texts</u>. It is testing for recall ability</li>
	<li>BLEU (Bilingual Evaluation Understudy): primarily used for <u>machine translation</u>. How closely a generated translations matches a reference by comparing word sequence.</li>
	<li>BERTScore: evaluates the <u>quality of the text</u> generator by leveraging embbeding. It used pre-trained Burt models or bi-directional encoder representations from transformers.</li>
</ul>

How well Foundation models meet business objectives:
<ul>
	<li>productivity: high output quality with minimum human intervention</li>
	<li>user engagement: how often and deeply users interact with the model </li>
	<li>task engineering: how effective the model can complete specific tasks</li>
</ul> 


<!-- ######################## -->

<br />
<hr>
<br />
<h3>References</h3>
<ul>
  <li><a href="">[NEW] Ultimate AWS Certified AI Practitioner AIF-C01</a></li>
  <li><a href="">Practice Exams | AWS Certified AI Practitioner (AIF-C01)</a></li>
  <li><a href="">[Practice Exams] AWS Certified AI Practitioner - AIF-C01</a></li>
  <li><a href="">CloudGuru</a></li>
  <li><a href="https://fvivas.com/19-formulas-e-estruturas-de-prompts-para-chatgpt/">Prompt Structure</a></li>
</ul>  

